"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[4541],{2493(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-4-vla/navigate-system","title":"NAVIGATE System for Autonomous Movement","description":"Overview","source":"@site/docs/module-4-vla/navigate-system.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/navigate-system","permalink":"/ai-native-book/docs/module-4-vla/navigate-system","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/navigate-system.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"LLM-4 Integration for Cognitive Planning","permalink":"/ai-native-book/docs/module-4-vla/llm-4-integration"},"next":{"title":"MANIPULATE System for Autonomous Manipulation","permalink":"/ai-native-book/docs/module-4-vla/manipulate-system"}}');var i=t(4848),o=t(3023);const s={sidebar_position:4},r="NAVIGATE System for Autonomous Movement",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Navigation Layer",id:"navigation-layer",level:3},{value:"Component Integration",id:"component-integration",level:3},{value:"Technical Implementation",id:"technical-implementation",level:2},{value:"Navigation Configuration",id:"navigation-configuration",level:3},{value:"Mapping and Localization",id:"mapping-and-localization",level:3},{value:"Path Planning Algorithm",id:"path-planning-algorithm",level:3},{value:"Dynamic Obstacle Avoidance",id:"dynamic-obstacle-avoidance",level:3},{value:"Navigation Execution Process",id:"navigation-execution-process",level:2},{value:"Goal Processing",id:"goal-processing",level:3},{value:"Controller Implementation",id:"controller-implementation",level:3},{value:"Safety and Validation",id:"safety-and-validation",level:2},{value:"Safety-First Navigation",id:"safety-first-navigation",level:3},{value:"Integration with VLA System",id:"integration-with-vla-system",level:2},{value:"Multi-modal Coordination",id:"multi-modal-coordination",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Adaptive Navigation",id:"adaptive-navigation",level:3},{value:"Error Handling and Recovery",id:"error-handling-and-recovery",level:2},{value:"Navigation Failure Management",id:"navigation-failure-management",level:3},{value:"Future Enhancements",id:"future-enhancements",level:2},{value:"Advanced Capabilities",id:"advanced-capabilities",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"navigate-system-for-autonomous-movement",children:"NAVIGATE System for Autonomous Movement"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"The NAVIGATE system provides autonomous movement capabilities for the Vision-Language-Action (VLA) system, enabling humanoid robots to navigate complex environments safely and efficiently. This system integrates with the cognitive planning layer to execute navigation commands generated from natural language input while maintaining safety and adaptability to dynamic environments."}),"\n",(0,i.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,i.jsx)(n.h3,{id:"navigation-layer",children:"Navigation Layer"}),"\n",(0,i.jsx)(n.p,{children:"The NAVIGATE system operates as the autonomous movement component that processes navigation goals and generates safe, efficient paths:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Navigation Goal \u2192 Path Planning \u2192 Obstacle Avoidance \u2192 Motion Execution \u2192 Position Verification\n"})}),"\n",(0,i.jsx)(n.h3,{id:"component-integration",children:"Component Integration"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Goal Interface"}),": Receiving navigation targets from cognitive planning"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mapping System"}),": Environmental representation and localization"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Path Planner"}),": Generating optimal paths considering constraints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Controller"}),": Executing navigation commands with precision"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Safety Monitor"}),": Ensuring safe navigation throughout execution"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"technical-implementation",children:"Technical Implementation"}),"\n",(0,i.jsx)(n.h3,{id:"navigation-configuration",children:"Navigation Configuration"}),"\n",(0,i.jsx)(n.p,{children:"The NAVIGATE system is configured for optimal autonomous movement:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'navigate:\n  path_planning:\n    planner: "navfn"              # Global path planner\n    local_planner: "dwa_local_planner"  # Local path planner\n    planner_frequency: 0.5        # Hz, frequency of global plan updates\n    controller_frequency: 20.0    # Hz, frequency of local control updates\n\n  obstacle_handling:\n    inflation_radius: 0.55        # Meters, safety buffer around obstacles\n    cost_factor: 3.0              # Weight for obstacle cost\n    max_obstacle_height: 2.0      # Meters, maximum obstacle height to consider\n\n  movement_constraints:\n    max_vel_x: 0.5                # m/s, maximum forward velocity\n    min_vel_x: 0.05               # m/s, minimum forward velocity\n    max_vel_theta: 1.0            # rad/s, maximum angular velocity\n    min_in_place_vel_theta: 0.4   # rad/s, minimum in-place turning speed\n\n  safety:\n    escape_vel: -0.1              # m/s, backward speed for escape maneuvers\n    oscillation_timeout: 30.0     # seconds, time limit for oscillation detection\n    oscillation_distance: 0.5     # meters, distance threshold for oscillation\n'})}),"\n",(0,i.jsx)(n.h3,{id:"mapping-and-localization",children:"Mapping and Localization"}),"\n",(0,i.jsx)(n.p,{children:"The system maintains accurate environmental representation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class NavigationMapper:\n    def __init__(self):\n        self.map_resolution = 0.05  # meters per pixel\n        self.map_width = 200        # pixels\n        self.map_height = 200       # pixels\n        self.origin = (0, 0, 0)     # x, y, theta in meters and radians\n        self.costmap = None         # 2D array of cost values\n        self.known_obstacles = {}   # Dictionary of persistent obstacles\n\n    def update_map(self, sensor_data):\n        """Update map with new sensor information"""\n        # Process LIDAR data for obstacle detection\n        lidar_points = sensor_data.get(\'lidar\', [])\n        new_obstacles = self._detect_obstacles(lidar_points)\n\n        # Update costmap with new obstacles\n        self._update_costmap(new_obstacles)\n\n        # Update known obstacles database\n        self._update_known_obstacles(new_obstacles)\n\n    def get_traversable_area(self, robot_radius):\n        """Get areas traversable by robot of given radius"""\n        # Implementation to find areas clear of obstacles\n        # considering robot footprint\n        pass\n'})}),"\n",(0,i.jsx)(n.h3,{id:"path-planning-algorithm",children:"Path Planning Algorithm"}),"\n",(0,i.jsx)(n.p,{children:"The system implements sophisticated path planning:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom heapq import heappush, heappop\n\nclass PathPlanner:\n    def __init__(self, costmap, resolution=0.05):\n        self.costmap = costmap\n        self.resolution = resolution\n        self.grid = None\n\n    def plan_path(self, start, goal, robot_radius=0.3):\n        """Plan path from start to goal using A* algorithm"""\n        start_grid = self._world_to_grid(start)\n        goal_grid = self._world_to_grid(goal)\n\n        # Inflate robot radius in costmap\n        inflated_costmap = self._inflate_robot_radius(robot_radius)\n\n        # Implement A* pathfinding\n        open_set = [(0, start_grid)]\n        came_from = {}\n        g_score = {start_grid: 0}\n        f_score = {start_grid: self._heuristic(start_grid, goal_grid)}\n\n        while open_set:\n            current = heappop(open_set)[1]\n\n            if current == goal_grid:\n                return self._reconstruct_path(came_from, current)\n\n            for neighbor in self._get_neighbors(current):\n                if self._is_traversable(neighbor, inflated_costmap):\n                    tentative_g = g_score[current] + self._distance(current, neighbor)\n\n                    if neighbor not in g_score or tentative_g < g_score[neighbor]:\n                        came_from[neighbor] = current\n                        g_score[neighbor] = tentative_g\n                        f_score[neighbor] = tentative_g + self._heuristic(neighbor, goal_grid)\n                        heappush(open_set, (f_score[neighbor], neighbor))\n\n        return None  # No path found\n\n    def _heuristic(self, a, b):\n        """Calculate heuristic distance (Euclidean)"""\n        return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"dynamic-obstacle-avoidance",children:"Dynamic Obstacle Avoidance"}),"\n",(0,i.jsx)(n.p,{children:"The system handles moving obstacles in real-time:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class DynamicObstacleAvoider:\n    def __init__(self):\n        self.tracked_obstacles = {}  # Moving obstacles with velocity vectors\n        self.prediction_horizon = 2.0  # seconds to predict obstacle movement\n        self.safety_buffer = 0.3  # meters safety distance\n\n    def update_obstacle_predictions(self, detection_data):\n        \"\"\"Update predictions for moving obstacles\"\"\"\n        for detection in detection_data:\n            obstacle_id = detection['id']\n            position = detection['position']\n            velocity = detection['velocity']\n\n            # Update obstacle state\n            if obstacle_id not in self.tracked_obstacles:\n                self.tracked_obstacles[obstacle_id] = {\n                    'positions': [position],\n                    'velocities': [velocity],\n                    'predicted_path': []\n                }\n            else:\n                # Update tracking with new data\n                self.tracked_obstacles[obstacle_id]['positions'].append(position)\n                self.tracked_obstacles[obstacle_id]['velocities'].append(velocity)\n\n                # Predict future positions\n                self._predict_future_positions(obstacle_id)\n\n    def _predict_future_positions(self, obstacle_id):\n        \"\"\"Predict obstacle positions in the future\"\"\"\n        obstacle = self.tracked_obstacles[obstacle_id]\n        current_pos = obstacle['positions'][-1]\n        velocity = obstacle['velocities'][-1]\n\n        predicted_path = []\n        for t in np.arange(0, self.prediction_horizon, 0.1):\n            future_pos = (\n                current_pos[0] + velocity[0] * t,\n                current_pos[1] + velocity[1] * t\n            )\n            predicted_path.append(future_pos)\n\n        obstacle['predicted_path'] = predicted_path\n\n    def adjust_path_for_moving_obstacles(self, path, current_time):\n        \"\"\"Adjust path based on predicted moving obstacles\"\"\"\n        # Implementation to modify path based on moving obstacle predictions\n        # This might involve replanning or local adjustments\n        adjusted_path = []\n\n        for point in path:\n            # Check if point conflicts with predicted obstacle positions\n            safe = True\n            for obstacle_id, obstacle in self.tracked_obstacles.items():\n                for future_pos in obstacle['predicted_path']:\n                    distance = self._distance(point, future_pos)\n                    if distance < self.safety_buffer:\n                        safe = False\n                        break\n                if not safe:\n                    break\n\n            if safe:\n                adjusted_path.append(point)\n            else:\n                # Implement local avoidance maneuver\n                adjusted_point = self._find_safe_alternative(point)\n                adjusted_path.append(adjusted_point)\n\n        return adjusted_path\n"})}),"\n",(0,i.jsx)(n.h2,{id:"navigation-execution-process",children:"Navigation Execution Process"}),"\n",(0,i.jsx)(n.h3,{id:"goal-processing",children:"Goal Processing"}),"\n",(0,i.jsx)(n.p,{children:"The system processes navigation goals from cognitive planning:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class NavigationGoalProcessor:\n    def __init__(self):\n        self.path_planner = PathPlanner()\n        self.controller = NavigationController()\n        self.safety_monitor = SafetyMonitor()\n\n    def execute_navigation_goal(self, goal_specification):\n        """Execute navigation goal with safety monitoring"""\n        # Parse goal specification from cognitive planning\n        target_location = self._parse_goal_location(goal_specification)\n\n        # Verify target location is reachable\n        if not self._is_location_reachable(target_location):\n            raise NavigationError(f"Location {target_location} is not reachable")\n\n        # Plan path to target\n        current_pose = self._get_current_pose()\n        path = self.path_planner.plan_path(current_pose, target_location)\n\n        if not path:\n            raise NavigationError(f"No valid path found to {target_location}")\n\n        # Execute navigation with safety monitoring\n        return self._execute_path_with_monitoring(path, goal_specification)\n\n    def _parse_goal_location(self, goal_specification):\n        """Parse natural language goal into coordinate location"""\n        # Implementation to convert natural language descriptions\n        # like "kitchen table" or "near the door" into coordinates\n        # This would interface with the mapping system to resolve\n        # semantic location descriptions\n        pass\n'})}),"\n",(0,i.jsx)(n.h3,{id:"controller-implementation",children:"Controller Implementation"}),"\n",(0,i.jsx)(n.p,{children:"The navigation controller executes movement commands:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class NavigationController:\n    def __init__(self):\n        self.linear_vel_tolerance = 0.1  # m/s\n        self.angular_vel_tolerance = 0.1  # rad/s\n        self.position_tolerance = 0.2  # meters\n        self.angle_tolerance = 0.1  # radians\n\n    def follow_path(self, path, goal_tolerance=0.3):\n        """Follow a planned path with precise control"""\n        for i, waypoint in enumerate(path):\n            # Move to waypoint with obstacle avoidance\n            success = self._move_to_waypoint(waypoint)\n\n            if not success:\n                # Handle navigation failure\n                return self._handle_navigation_failure(path, i)\n\n            # Check if this is the final waypoint\n            if i == len(path) - 1:\n                # Final goal reached\n                return self._verify_goal_achievement(waypoint, goal_tolerance)\n\n        return True\n\n    def _move_to_waypoint(self, waypoint):\n        """Move robot to a specific waypoint"""\n        # Calculate desired velocity based on current position and waypoint\n        current_pose = self._get_current_pose()\n\n        # Calculate error\n        linear_error = self._calculate_linear_error(current_pose, waypoint)\n        angular_error = self._calculate_angular_error(current_pose, waypoint)\n\n        # Apply control law (simple proportional control example)\n        linear_vel = min(linear_error * 0.5, 0.5)  # Limit to 0.5 m/s\n        angular_vel = angular_error * 2.0  # Proportional gain of 2.0\n\n        # Send velocity commands\n        self._send_velocity_commands(linear_vel, angular_vel)\n\n        # Monitor progress and adjust as needed\n        return self._monitor_progress(waypoint)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"safety-and-validation",children:"Safety and Validation"}),"\n",(0,i.jsx)(n.h3,{id:"safety-first-navigation",children:"Safety-First Navigation"}),"\n",(0,i.jsx)(n.p,{children:"The system implements safety-first navigation principles:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SafetyMonitor:\n    def __init__(self):\n        self.emergency_stop_distance = 0.3  # meters\n        self.max_navigation_time = 300  # seconds (5 minutes)\n        self.position_accuracy_threshold = 0.5  # meters\n\n    def validate_navigation_plan(self, path):\n        """Validate navigation plan for safety"""\n        safety_check = {\n            \'is_safe\': True,\n            \'violations\': [],\n            \'warnings\': []\n        }\n\n        # Check path doesn\'t go through restricted areas\n        for point in path:\n            if self._is_restricted_area(point):\n                safety_check[\'is_safe\'] = False\n                safety_check[\'violations\'].append(f"Path enters restricted area at {point}")\n\n        # Check path length is reasonable\n        path_length = self._calculate_path_length(path)\n        if path_length > self._get_max_safe_distance():\n            safety_check[\'warnings\'].append(f"Path length ({path_length}m) is long")\n\n        # Check path avoids safety-critical obstacles\n        for point in path:\n            if self._is_too_close_to_critical_obstacle(point):\n                safety_check[\'is_safe\'] = False\n                safety_check[\'violations\'].append(f"Path too close to critical obstacle at {point}")\n\n        return safety_check\n\n    def _is_restricted_area(self, point):\n        """Check if point is in a restricted area"""\n        # Implementation to check against restricted area database\n        return False\n'})}),"\n",(0,i.jsx)(n.h2,{id:"integration-with-vla-system",children:"Integration with VLA System"}),"\n",(0,i.jsx)(n.h3,{id:"multi-modal-coordination",children:"Multi-modal Coordination"}),"\n",(0,i.jsx)(n.p,{children:"The NAVIGATE system coordinates with other VLA components:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"// VLA navigation coordination\nclass VLAOrchestrator {\n  constructor() {\n    this.navigate = new NavigationSystem();\n    this.vision = new VisionSystem();\n    this.llm4 = new LLM4Interface();\n    this.manipulate = new ManipulationSystem();\n  }\n\n  async executeNavigationCommand(command) {\n    // 1. Parse command with LLM-4 to extract navigation goal\n    const navigationGoal = await this.llm4.extractNavigationGoal(command);\n\n    // 2. Validate goal with vision system\n    const validation = await this.vision.validateNavigationGoal(navigationGoal);\n    if (!validation.isReachable) {\n      throw new Error(`Navigation goal not reachable: ${navigationGoal}`);\n    }\n\n    // 3. Execute navigation with safety monitoring\n    const result = await this.navigate.executeGoal(navigationGoal);\n\n    // 4. Update context for next actions\n    await this._updateContextAfterNavigation(result);\n\n    return result;\n  }\n\n  async _updateContextAfterNavigation(result) {\n    // Update system context with new position and environment observations\n    const environmentUpdate = await this.vision.scanEnvironment();\n    await this.llm4.updateContext({\n      position: result.finalPosition,\n      environment: environmentUpdate\n    });\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsx)(n.h3,{id:"adaptive-navigation",children:"Adaptive Navigation"}),"\n",(0,i.jsx)(n.p,{children:"The system adapts navigation parameters based on environment:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class AdaptiveNavigation:\n    def __init__(self):\n        self.environment_types = {\n            'open_space': {'max_vel': 0.8, 'safety_buffer': 0.3},\n            'cluttered': {'max_vel': 0.3, 'safety_buffer': 0.6},\n            'narrow_corridor': {'max_vel': 0.2, 'safety_buffer': 0.4},\n            'dynamic': {'max_vel': 0.4, 'safety_buffer': 0.8}\n        }\n\n    def adapt_to_environment(self, environment_data):\n        \"\"\"Adapt navigation parameters based on environment type\"\"\"\n        env_type = self._classify_environment(environment_data)\n        params = self.environment_types[env_type]\n\n        # Adjust navigation parameters\n        self.max_velocity = params['max_vel']\n        self.safety_buffer = params['safety_buffer']\n\n        # Update obstacle detection thresholds\n        self._update_obstacle_detection_params(env_type)\n\n    def _classify_environment(self, environment_data):\n        \"\"\"Classify environment based on sensor data\"\"\"\n        obstacle_density = environment_data.get('obstacle_density', 0)\n        corridor_width = environment_data.get('corridor_width', float('inf'))\n        moving_objects = environment_data.get('moving_objects', 0)\n\n        if moving_objects > 5:\n            return 'dynamic'\n        elif obstacle_density > 0.3:\n            return 'cluttered'\n        elif corridor_width < 1.0:\n            return 'narrow_corridor'\n        else:\n            return 'open_space'\n"})}),"\n",(0,i.jsx)(n.h2,{id:"error-handling-and-recovery",children:"Error Handling and Recovery"}),"\n",(0,i.jsx)(n.h3,{id:"navigation-failure-management",children:"Navigation Failure Management"}),"\n",(0,i.jsx)(n.p,{children:"The system handles navigation failures gracefully:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class NavigationFailureManager:\n    def __init__(self):\n        self.recovery_strategies = [\n            'replan_with_obstacle_avoidance',\n            'use_alternative_path',\n            'request_human_assistance',\n            'return_to_known_safe_location'\n        ]\n\n    def handle_navigation_failure(self, failure_type, current_state, goal):\n        \"\"\"Handle navigation failure and determine recovery strategy\"\"\"\n        if failure_type == 'obstacle_blockage':\n            # Try to find alternative path around obstacle\n            alternative_path = self._find_alternative_path(current_state, goal)\n            if alternative_path:\n                return alternative_path\n\n        elif failure_type == 'local_minima':\n            # Use exploration to escape local minima\n            escape_path = self._generate_escape_path(current_state)\n            if escape_path:\n                return escape_path\n\n        elif failure_type == 'timeout':\n            # Return to last known safe location\n            safe_location = self._get_last_safe_location()\n            return self._generate_path_to_safe_location(safe_location)\n\n        # If no automatic recovery possible, escalate\n        return self._escalate_to_human(current_state, goal)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"future-enhancements",children:"Future Enhancements"}),"\n",(0,i.jsx)(n.h3,{id:"advanced-capabilities",children:"Advanced Capabilities"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multi-floor Navigation"}),": Extend to multi-story buildings with elevator handling"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Social Navigation"}),": Navigate safely around humans with social conventions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Learning-based Adaptation"}),": Improve navigation through experience"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Collaborative Navigation"}),": Coordinate with other robots for complex tasks"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This NAVIGATE system provides the autonomous movement capabilities for the VLA system, enabling humanoid robots to navigate complex environments safely and efficiently based on natural language commands."})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},3023(e,n,t){t.d(n,{R:()=>s,x:()=>r});var a=t(6540);const i={},o=a.createContext(i);function s(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);