"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[9592],{3023(e,n,t){t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const r={},s=i.createContext(r);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:n},e.children)}},4948(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-1-nervous-system/nord-content","title":"NORD: NVIDIA Omniverse Robot Definition","description":"Overview","source":"@site/docs/module-1-nervous-system/nord-content.md","sourceDirName":"module-1-nervous-system","slug":"/module-1-nervous-system/nord-content","permalink":"/ai-native-book/docs/module-1-nervous-system/nord-content","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-nervous-system/nord-content.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"ROS-II Fundamentals: Middleware Architecture","permalink":"/ai-native-book/docs/module-1-nervous-system/ros-ii-fundamentals"},"next":{"title":"NORD\'s Replay System: Simulation Data Recording and Playback","permalink":"/ai-native-book/docs/module-1-nervous-system/nord-replay-system"}}');var r=t(4848),s=t(3023);const o={sidebar_position:3},a="NORD: NVIDIA Omniverse Robot Definition",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Architecture and Components",id:"architecture-and-components",level:2},{value:"NORD Framework Structure",id:"nord-framework-structure",level:3},{value:"Core Components",id:"core-components",level:3},{value:"1. Extended Robot Description",id:"1-extended-robot-description",level:4},{value:"2. Physics Simulation Integration",id:"2-physics-simulation-integration",level:4},{value:"3. Material and Appearance System",id:"3-material-and-appearance-system",level:4},{value:"NORD Integration with Omniverse",id:"nord-integration-with-omniverse",level:2},{value:"USD (Universal Scene Description)",id:"usd-universal-scene-description",level:3},{value:"Sensor Integration",id:"sensor-integration",level:3},{value:"NORD Replay System",id:"nord-replay-system",level:2},{value:"Data Recording",id:"data-recording",level:3},{value:"Data Playback",id:"data-playback",level:3},{value:"Best Practices for NORD Implementation",id:"best-practices-for-nord-implementation",level:2},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Quality Assurance",id:"quality-assurance",level:3},{value:"Integration Guidelines",id:"integration-guidelines",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"nord-nvidia-omniverse-robot-definition",children:"NORD: NVIDIA Omniverse Robot Definition"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"NVIDIA Omniverse Robot Definition (NORD) represents a comprehensive framework for defining, simulating, and deploying robotic systems within the NVIDIA Omniverse platform. NORD bridges the gap between robot design and simulation, providing a standardized approach to create digital twins of robotic systems that can be used for development, testing, and validation before physical deployment."}),"\n",(0,r.jsx)(n.h2,{id:"architecture-and-components",children:"Architecture and Components"}),"\n",(0,r.jsx)(n.h3,{id:"nord-framework-structure",children:"NORD Framework Structure"}),"\n",(0,r.jsx)(n.p,{children:"NORD is built on several key components that work together to create comprehensive robot definitions:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              NORD Framework             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502    Robot Description Format       \u2502  \u2502\n\u2502  \u2502  (Extended URDF/SDF Integration)  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502   Physics       \u2502 \u2502   Materials     \u2502\u2502\n\u2502  \u2502   Simulation    \u2502 \u2502   Definition    \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502   Sensor        \u2502 \u2502   Actuator      \u2502\u2502\n\u2502  \u2502   Modeling      \u2502 \u2502   Integration   \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502    Omniverse Integration Layer    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h3,{id:"core-components",children:"Core Components"}),"\n",(0,r.jsx)(n.h4,{id:"1-extended-robot-description",children:"1. Extended Robot Description"}),"\n",(0,r.jsx)(n.p,{children:"NORD extends traditional robot description formats with Omniverse-specific capabilities:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "robot": {\n    "name": "example_robot",\n    "version": "1.0",\n    "description": "Example robot for NORD demonstration",\n    "links": [\n      {\n        "name": "base_link",\n        "visual": {\n          "mesh": "package://robot_description/meshes/base_link.stl",\n          "material": "metal_chrome"\n        },\n        "collision": {\n          "mesh": "package://robot_description/meshes/base_link_collision.stl"\n        },\n        "inertial": {\n          "mass": 10.0,\n          "inertia": {\n            "ixx": 0.4,\n            "ixy": 0.0,\n            "ixz": 0.0,\n            "iyy": 0.4,\n            "iyz": 0.0,\n            "izz": 0.2\n          }\n        }\n      }\n    ],\n    "joints": [\n      {\n        "name": "joint1",\n        "type": "revolute",\n        "parent": "base_link",\n        "child": "link1",\n        "origin": {\n          "xyz": [0.0, 0.0, 0.1],\n          "rpy": [0.0, 0.0, 0.0]\n        },\n        "axis": [0, 0, 1],\n        "limits": {\n          "lower": -3.14,\n          "upper": 3.14,\n          "effort": 100,\n          "velocity": 1.0\n        }\n      }\n    ]\n  },\n  "omniverse": {\n    "articulation": {\n      "enable_self_collision": true,\n      "fix_root_link": false\n    },\n    "materials": {\n      "metal_chrome": {\n        "albedo": [0.8, 0.8, 0.9],\n        "metallic": 0.9,\n        "roughness": 0.1,\n        "specular": 0.5\n      }\n    },\n    "sensors": [\n      {\n        "name": "camera_sensor",\n        "type": "camera",\n        "parent_link": "sensor_mount",\n        "position": [0.1, 0.0, 0.05],\n        "orientation": [0.0, 0.0, 0.0, 1.0],\n        "parameters": {\n          "resolution": [640, 480],\n          "fov": 1.047,\n          "clipping_range": [0.1, 100.0]\n        }\n      }\n    ]\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"2-physics-simulation-integration",children:"2. Physics Simulation Integration"}),"\n",(0,r.jsx)(n.p,{children:"NORD provides advanced physics simulation capabilities:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class NORDPhysicsIntegrator:\n    def __init__(self, robot_config):\n        self.robot = self.load_robot(robot_config)\n        self.physics_scene = self.create_physics_scene()\n        self.contact_manager = self.setup_contact_manager()\n\n    def load_robot(self, config):\n        """Load robot with NORD extensions"""\n        # Load base URDF/SDF\n        robot = self.load_base_description(config[\'urdf_path\'])\n\n        # Apply NORD-specific physics properties\n        for link in robot.links:\n            self.apply_material_properties(link, config[\'materials\'])\n            self.setup_collision_properties(link, config[\'collision\'])\n\n        return robot\n\n    def create_physics_scene(self):\n        """Create physics scene with Omniverse integration"""\n        scene = PhysicsScene(\n            gravity=[0, 0, -9.81],\n            solver_type=\'tgs\',  # Time-stepping Gauss-Seidel\n            num_position_iterations=4,\n            num_velocity_iterations=1\n        )\n\n        # Add NORD-specific constraints\n        scene.set_contact_offset(0.001)\n        scene.set_rest_offset(0.0)\n\n        return scene\n\n    def setup_contact_manager(self):\n        """Setup advanced contact handling"""\n        contact_manager = ContactManager()\n\n        # Register contact callbacks for NORD-specific behaviors\n        contact_manager.register_callback(\n            \'robot_environment\',\n            self.handle_robot_environment_contact\n        )\n        contact_manager.register_callback(\n            \'robot_robot\',\n            self.handle_robot_robot_contact\n        )\n\n        return contact_manager\n'})}),"\n",(0,r.jsx)(n.h4,{id:"3-material-and-appearance-system",children:"3. Material and Appearance System"}),"\n",(0,r.jsx)(n.p,{children:"NORD includes advanced material definitions for photorealistic rendering:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class NORDMaterialSystem:\n    def __init__(self):\n        self.material_library = {}\n        self.pbr_properties = {}\n\n    def define_material(self, name, properties):\n        \"\"\"Define material with Physically Based Rendering properties\"\"\"\n        material = {\n            'name': name,\n            'albedo': properties.get('albedo', [0.8, 0.8, 0.8]),\n            'metallic': properties.get('metallic', 0.0),\n            'roughness': properties.get('roughness', 0.5),\n            'normal_map': properties.get('normal_map'),\n            'occlusion_map': properties.get('occlusion_map'),\n            'emissive': properties.get('emissive', [0.0, 0.0, 0.0]),\n            'transmission': properties.get('transmission', 0.0),\n            'ior': properties.get('ior', 1.5)\n        }\n\n        self.material_library[name] = material\n        return material\n\n    def apply_material_to_link(self, link, material_name):\n        \"\"\"Apply material to robot link\"\"\"\n        if material_name in self.material_library:\n            material = self.material_library[material_name]\n            # Apply to visual mesh in Omniverse\n            self.set_visual_material(link.visual_mesh, material)\n            return True\n        return False\n"})}),"\n",(0,r.jsx)(n.h2,{id:"nord-integration-with-omniverse",children:"NORD Integration with Omniverse"}),"\n",(0,r.jsx)(n.h3,{id:"usd-universal-scene-description",children:"USD (Universal Scene Description)"}),"\n",(0,r.jsx)(n.p,{children:"NORD leverages USD for scene representation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from pxr import Usd, UsdGeom, Sdf\n\nclass NORDUSDExporter:\n    def __init__(self, stage_path):\n        self.stage = Usd.Stage.CreateNew(stage_path)\n        self.root_prim = self.stage.GetPseudoRoot()\n\n    def export_robot(self, robot_config):\n        \"\"\"Export robot to USD format\"\"\"\n        robot_prim = UsdGeom.Xform.Define(self.stage, '/Robot')\n\n        # Export links as Xform prims\n        for link_config in robot_config['links']:\n            link_prim = UsdGeom.Xform.Define(\n                self.stage,\n                f'/Robot/{link_config[\"name\"]}'\n            )\n\n            # Set transform\n            xform_api = UsdGeom.XformCommonAPI(link_prim)\n            xform_api.SetTranslate(link_config['origin']['xyz'])\n\n            # Add mesh\n            if 'mesh' in link_config['visual']:\n                mesh_prim = UsdGeom.Mesh.Define(\n                    self.stage,\n                    f'/Robot/{link_config[\"name\"]}/visual'\n                )\n                self.set_mesh_properties(mesh_prim, link_config['visual'])\n\n        # Export joints as articulation joints\n        self.export_joints(robot_config['joints'])\n\n        self.stage.GetRootLayer().Save()\n\n    def export_joints(self, joints):\n        \"\"\"Export joints with articulation properties\"\"\"\n        for joint_config in joints:\n            joint_prim = UsdGeom.Xform.Define(\n                self.stage,\n                f'/Robot/Joints/{joint_config[\"name\"]}'\n            )\n\n            # Apply articulation joint properties\n            articulation_joint = PhysxSchema.Joint.Define(\n                self.stage,\n                joint_prim.GetPath()\n            )\n            self.set_joint_properties(articulation_joint, joint_config)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"sensor-integration",children:"Sensor Integration"}),"\n",(0,r.jsx)(n.p,{children:"NORD provides comprehensive sensor modeling:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class NORDSensorIntegrator:\n    def __init__(self):\n        self.sensor_types = {\n            'camera': self.create_camera_sensor,\n            'lidar': self.create_lidar_sensor,\n            'imu': self.create_imu_sensor,\n            'force_torque': self.create_force_torque_sensor\n        }\n\n    def create_camera_sensor(self, config):\n        \"\"\"Create Omniverse-compatible camera sensor\"\"\"\n        camera = omni.replicator.core.Camera()\n        camera.set_resolution(config['parameters']['resolution'])\n        camera.set_fov(config['parameters']['fov'])\n        camera.set_clipping_range(config['parameters']['clipping_range'])\n\n        return {\n            'sensor': camera,\n            'config': config,\n            'data_provider': omni.replicator.core.RandomIntrinsicsCameraProvider()\n        }\n\n    def create_lidar_sensor(self, config):\n        \"\"\"Create Omniverse-compatible LIDAR sensor\"\"\"\n        lidar = omni.isaac.range_sensor.acquire_lidar_sensor_interface()\n\n        return {\n            'sensor': lidar,\n            'config': config,\n            'spec': {\n                'min_range': config['parameters'].get('min_range', 0.1),\n                'max_range': config['parameters'].get('max_range', 10.0),\n                'rotation_frequency': config['parameters'].get('rotation_frequency', 10),\n                'channels': config['parameters'].get('channels', 16)\n            }\n        }\n\n    def integrate_sensors(self, robot_prim, sensor_configs):\n        \"\"\"Integrate sensors into robot structure\"\"\"\n        for sensor_config in sensor_configs:\n            sensor_type = sensor_config['type']\n            if sensor_type in self.sensor_types:\n                sensor_instance = self.sensor_types[sensor_type](sensor_config)\n\n                # Attach sensor to parent link\n                parent_link_path = f'/Robot/{sensor_config[\"parent_link\"]}'\n                sensor_prim = self.stage.DefinePrim(\n                    f'{parent_link_path}/{sensor_config[\"name\"]}',\n                    'Xform'\n                )\n\n                # Set sensor transform\n                transform_api = UsdGeom.XformCommonAPI(sensor_prim)\n                transform_api.SetTranslate(sensor_config['position'])\n                transform_api.SetRotate Orient(sensor_config['orientation'])\n"})}),"\n",(0,r.jsx)(n.h2,{id:"nord-replay-system",children:"NORD Replay System"}),"\n",(0,r.jsx)(n.p,{children:"The NORD Replay system enables recording and playback of robot simulation data for analysis and debugging."}),"\n",(0,r.jsx)(n.h3,{id:"data-recording",children:"Data Recording"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class NORDReplayRecorder:\n    def __init__(self, robot, output_path):\n        self.robot = robot\n        self.output_path = output_path\n        self.recording_data = {\n            'timestamps': [],\n            'joint_states': [],\n            'sensor_data': [],\n            'environment_state': [],\n            'control_commands': []\n        }\n        self.is_recording = False\n\n    def start_recording(self):\n        \"\"\"Start recording robot simulation data\"\"\"\n        self.is_recording = True\n        self.start_time = time.time()\n        self.record_initial_state()\n\n    def record_frame(self):\n        \"\"\"Record current simulation frame\"\"\"\n        if not self.is_recording:\n            return\n\n        current_time = time.time() - self.start_time\n        self.recording_data['timestamps'].append(current_time)\n\n        # Record joint states\n        joint_states = {}\n        for joint in self.robot.joints:\n            joint_states[joint.name] = {\n                'position': joint.get_position(),\n                'velocity': joint.get_velocity(),\n                'effort': joint.get_effort()\n            }\n        self.recording_data['joint_states'].append(joint_states)\n\n        # Record sensor data\n        sensor_data = {}\n        for sensor_name, sensor in self.robot.sensors.items():\n            sensor_data[sensor_name] = sensor.get_data()\n        self.recording_data['sensor_data'].append(sensor_data)\n\n    def stop_recording(self):\n        \"\"\"Stop recording and save data\"\"\"\n        self.is_recording = False\n\n        # Save recording data to file\n        with open(self.output_path, 'wb') as f:\n            pickle.dump(self.recording_data, f)\n\n        print(f\"Recording saved to {self.output_path}\")\n"})}),"\n",(0,r.jsx)(n.h3,{id:"data-playback",children:"Data Playback"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class NORDReplayPlayer:\n    def __init__(self, recording_path):\n        self.recording_path = recording_path\n        self.recording_data = self.load_recording()\n        self.current_frame = 0\n        self.playback_speed = 1.0\n\n    def load_recording(self):\n        """Load recording data from file"""\n        with open(self.recording_path, \'rb\') as f:\n            return pickle.load(f)\n\n    def play_frame(self, target_robot):\n        """Play back a single frame of recording"""\n        if self.current_frame >= len(self.recording_data[\'timestamps\']):\n            return False  # End of recording\n\n        # Apply joint states\n        joint_states = self.recording_data[\'joint_states\'][self.current_frame]\n        for joint_name, state in joint_states.items():\n            target_robot.set_joint_position(joint_name, state[\'position\'])\n            target_robot.set_joint_velocity(joint_name, state[\'velocity\'])\n\n        # Apply sensor data (for visualization/analysis)\n        sensor_data = self.recording_data[\'sensor_data\'][self.current_frame]\n\n        self.current_frame += 1\n        return True\n\n    def play_sequence(self, target_robot, callback=None):\n        """Play back entire sequence"""\n        self.current_frame = 0\n\n        while self.current_frame < len(self.recording_data[\'timestamps\']):\n            success = self.play_frame(target_robot)\n            if not success:\n                break\n\n            if callback:\n                callback(self.current_frame, len(self.recording_data[\'timestamps\']))\n\n            time.sleep(0.01 / self.playback_speed)  # Simulate real-time playback\n'})}),"\n",(0,r.jsx)(n.h2,{id:"best-practices-for-nord-implementation",children:"Best Practices for NORD Implementation"}),"\n",(0,r.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use level-of-detail (LOD) models for complex robots"}),"\n",(0,r.jsx)(n.li,{children:"Optimize mesh resolution based on use case"}),"\n",(0,r.jsx)(n.li,{children:"Implement efficient collision geometries"}),"\n",(0,r.jsx)(n.li,{children:"Use instancing for repeated components"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"quality-assurance",children:"Quality Assurance"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Validate robot kinematics before simulation"}),"\n",(0,r.jsx)(n.li,{children:"Test sensor configurations in isolation"}),"\n",(0,r.jsx)(n.li,{children:"Verify physics parameters with real-world data"}),"\n",(0,r.jsx)(n.li,{children:"Perform stress testing with extreme inputs"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"integration-guidelines",children:"Integration Guidelines"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Maintain compatibility with standard ROS/ROS2 interfaces"}),"\n",(0,r.jsx)(n.li,{children:"Use standard coordinate frames and units"}),"\n",(0,r.jsx)(n.li,{children:"Implement proper error handling and logging"}),"\n",(0,r.jsx)(n.li,{children:"Document custom extensions clearly"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"NORD provides a powerful framework for creating detailed robot definitions that integrate seamlessly with NVIDIA Omniverse, enabling sophisticated simulation and digital twin capabilities for physical AI applications."})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);